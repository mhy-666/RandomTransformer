_wandb:
    value:
        cli_version: 0.19.5
        m: []
        python_version: 3.10.19
        t:
            "1":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 51
                - 53
                - 55
                - 71
            "2":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 51
                - 53
                - 55
                - 71
            "3":
                - 13
                - 16
                - 23
                - 55
            "4": 3.10.19
            "5": 0.19.5
            "6": 4.57.1
            "8":
                - 5
            "12": 0.19.5
            "13": linux-x86_64
apply_random_backprop_to_layers:
    value: all
arch:
    value: transformer
device:
    value: cuda
disable_random_bp_at_ratio:
    value: 1
embedding_mix:
    value: 0.5
embedding_swap:
    value: ""
eval_lambada_samples:
    value: 1000
eval_nq_samples:
    value: 1000
eval_wikitext_samples:
    value: 1000
freeze_layers:
    value: ""
freeze_qkv_components:
    value: all
freeze_strategy_override:
    value: null
from_scratch:
    value: true
gradient_accumulation_steps:
    value: 4
identity_alpha:
    value: 0.8
identity_beta:
    value: 0.2
layer_ablate:
    value: -1
layer_patch:
    value: -1
learning_rate:
    value: 0.0005
load_pretrained_path:
    value: null
logging_steps:
    value: 50
max_length:
    value: 1024
max_steps:
    value: 80000
model_size:
    value: gpt2
output_dir:
    value: /work/hm235/random_transformer/outputs/from_scratch_33_larger_batch_size/baseline_0_zeroshot
pca_layer:
    value: -1
per_device_eval_batch_size:
    value: 4
per_device_train_batch_size:
    value: 128
project_name:
    value: gpt2_frozen_comprehensive
projection_rank:
    value: null
projection_type:
    value: random
qkv_identity_init:
    value: all
qkv_init_components:
    value: all
random_backprop_strategy:
    value: none
resample_every_batch:
    value: false
run_name:
    value: baseline_0_zeroshot_seed4
save_steps:
    value: 2000
seed:
    value: 4
share_attention_weights:
    value: false
share_mlp_weights:
    value: false
skip_training:
    value: true
train_epochs:
    value: 20
train_samples:
    value: 36718
warmup_steps:
    value: 1000
weight_decay:
    value: 0.01
weight_frozen:
    value: -1
