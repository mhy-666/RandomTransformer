{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Checkpoint Evolution Inference Script\n",
    "遍历单个实验文件夹下的所有checkpoint，评估不同训练步数的性能\n",
    "只评估WikiText-103 Perplexity\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "import re\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "def evaluate_wikitext103_ppl(model, tokenizer, device, max_length=1024):\n",
    "    \"\"\"评估WikiText-103 Perplexity\"\"\"\n",
    "    print(\"\\n[3/4] Evaluating WikiText-103...\")\n",
    "    test = load_dataset(\"wikitext\", \"wikitext-103-raw-v1\", split=\"train\")\n",
    "    encodings = tokenizer(\"\\n\\n\".join(test[\"text\"]), return_tensors=\"pt\")\n",
    "    max_length = max_length\n",
    "    stride = max_length\n",
    "    seq_len = encodings.input_ids.size(1)\n",
    "\n",
    "    nll_sum = 0.0\n",
    "    n_tokens = 0\n",
    "    prev_end_loc = 0\n",
    "    for begin_loc in tqdm(range(0, seq_len, stride)):\n",
    "        end_loc = min(begin_loc + max_length, seq_len)\n",
    "        trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
    "        input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
    "        target_ids = input_ids.clone()\n",
    "        target_ids[:, :-trg_len] = -100\n",
    "        # print(input_ids)\n",
    "        # print(target_ids)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=target_ids)\n",
    "\n",
    "            # loss is calculated using CrossEntropyLoss which averages over valid labels\n",
    "            # N.B. the model only calculates loss over trg_len - 1 labels, because it internally shifts the labels\n",
    "            # to the left by 1.\n",
    "            neg_log_likelihood = outputs.loss\n",
    "\n",
    "        # Accumulate the total negative log-likelihood and the total number of tokens\n",
    "        num_valid_tokens = (target_ids != -100).sum().item()  # number of valid tokens in target_ids\n",
    "        batch_size = target_ids.size(0)\n",
    "        num_loss_tokens = num_valid_tokens - batch_size  # subtract batch_size due to internal label shift\n",
    "        nll_sum += neg_log_likelihood * num_loss_tokens\n",
    "        n_tokens += num_loss_tokens\n",
    "\n",
    "        prev_end_loc = end_loc\n",
    "        if end_loc == seq_len:\n",
    "            break\n",
    "\n",
    "    avg_nll = nll_sum / n_tokens  # average negative log-likelihood per token\n",
    "    ppl = torch.exp(avg_nll)\n",
    "\n",
    "    ppl_value = ppl.item()\n",
    "    \n",
    "    print(f\"WikiText-103 PPL: {ppl_value:.2f}\")\n",
    "    return ppl_value\n",
    "\n",
    "\n",
    "def find_all_checkpoints(exp_dir, total_steps=None):\n",
    "    \"\"\"在实验文件夹下查找所有的checkpoint\"\"\"\n",
    "    exp_path = Path(exp_dir)\n",
    "    checkpoints = []\n",
    "    \n",
    "    print(f\"Searching for checkpoints in: {exp_dir}\")\n",
    "    \n",
    "    for ckpt_dir in exp_path.glob(\"checkpoint-*\"):\n",
    "        if ckpt_dir.is_dir():\n",
    "            match = re.search(r'checkpoint-(\\d+)', ckpt_dir.name)\n",
    "            if match:\n",
    "                step = int(match.group(1))\n",
    "                checkpoints.append((step, str(ckpt_dir)))\n",
    "    \n",
    "    final_model_path = exp_path / \"final_model\"\n",
    "    if final_model_path.exists() and final_model_path.is_dir():\n",
    "        final_step = total_steps if total_steps is not None else 999999\n",
    "        checkpoints.append((final_step, str(final_model_path)))\n",
    "    \n",
    "    checkpoints.sort(key=lambda x: x[0])\n",
    "    \n",
    "    print(f\"Found {len(checkpoints)} checkpoints\")\n",
    "    for step, path in checkpoints:\n",
    "        print(f\"  Step {step}: {Path(path).name}\")\n",
    "    \n",
    "    return checkpoints\n",
    "\n",
    "\n",
    "def load_model_and_tokenizer(model_path, device=\"cuda\"):\n",
    "    \"\"\"加载模型和tokenizer\"\"\"\n",
    "    try:\n",
    "        model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "        return model, tokenizer\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model from {model_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def evaluate_checkpoint(step, ckpt_path, args):\n",
    "    \"\"\"评估单个checkpoint\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Evaluating checkpoint at step {step}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    model, tokenizer = load_model_and_tokenizer(ckpt_path, args.device)\n",
    "    if model is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        ppl = evaluate_wikitext103_ppl(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            device=args.device,\n",
    "            max_length=args.max_length\n",
    "        )\n",
    "        \n",
    "        results = {\n",
    "            'step': step,\n",
    "            'checkpoint_path': ckpt_path,\n",
    "            'wikitext103_ppl': ppl\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating checkpoint at step {step}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    finally:\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "def plot_perplexity(df, output_dir):\n",
    "    \"\"\"绘制perplexity曲线\"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "    \n",
    "    ax.plot(df['step'], df['wikitext103_ppl'], marker='o', linewidth=2, markersize=6)\n",
    "    ax.set_xlabel('Training Steps', fontsize=12)\n",
    "    ax.set_ylabel('WikiText-103 Perplexity', fontsize=12)\n",
    "    ax.set_title('WikiText-103 Perplexity Evolution', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 标记最优点\n",
    "    best_idx = df['wikitext103_ppl'].idxmin()\n",
    "    best_step = df.loc[best_idx, 'step']\n",
    "    best_ppl = df.loc[best_idx, 'wikitext103_ppl']\n",
    "    ax.scatter([best_step], [best_ppl], color='green', s=200, \n",
    "              marker='*', zorder=5, label=f'Best: {best_ppl:.2f} @ step {best_step}')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plot_path = os.path.join(output_dir, 'checkpoint_evolution.png')\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nPlot saved to: {plot_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for checkpoints in: /work/hm235/random_transformer/outputs/from_scratch_40_minibatch_size_64_grad_accum_2/baseline_1_full_finetune/baseline_1_full_finetune_seed4_qkv_all\n",
      "Found 11 checkpoints\n",
      "  Step 2000: checkpoint-2000\n",
      "  Step 4000: checkpoint-4000\n",
      "  Step 6000: checkpoint-6000\n",
      "  Step 8000: checkpoint-8000\n",
      "  Step 10000: checkpoint-10000\n",
      "  Step 12000: checkpoint-12000\n",
      "  Step 14000: checkpoint-14000\n",
      "  Step 16000: checkpoint-16000\n",
      "  Step 18000: checkpoint-18000\n",
      "  Step 20000: checkpoint-20000\n",
      "  Step 20000: final_model\n",
      "\n",
      "Will evaluate 11 checkpoints\n",
      "\n",
      "================================================================================\n",
      "Evaluating checkpoint at step 2000\n",
      "================================================================================\n",
      "\n",
      "[3/4] Evaluating WikiText-103...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (119721489 > 1024). Running this sequence through the model will result in indexing errors\n",
      "  0%|          | 0/116916 [00:00<?, ?it/s]`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n",
      "  4%|▍         | 4388/116916 [2:35:48<44:39:04,  1.43s/it] "
     ]
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "# 定义参数\n",
    "EXP_DIR=\"/work/hm235/random_transformer/outputs/from_scratch_40_minibatch_size_64_grad_accum_2/baseline_1_full_finetune/baseline_1_full_finetune_seed4_qkv_all\"\n",
    "TOTAL_STEPS=20000  # 指定总训练步数\n",
    "OUTPUT_NAME=\"checkpoint_evolution\"\n",
    "args = Namespace(\n",
    "    exp_dir=EXP_DIR,  # 修改为你的实验目录\n",
    "    total_steps=TOTAL_STEPS,\n",
    "    output_name=OUTPUT_NAME,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    max_length=1024,\n",
    "    skip_plot=False,\n",
    "    start_step=0,\n",
    "    end_step=999999\n",
    ")\n",
    "\n",
    "\n",
    "# 查找checkpoints\n",
    "checkpoints = find_all_checkpoints(args.exp_dir, args.total_steps)\n",
    "\n",
    "if not checkpoints:\n",
    "    print(\"No checkpoints found!\")\n",
    "\n",
    "checkpoints = [(step, path) for step, path in checkpoints \n",
    "                if args.start_step <= step <= args.end_step]\n",
    "\n",
    "print(f\"\\nWill evaluate {len(checkpoints)} checkpoints\")\n",
    "\n",
    "# 评估所有checkpoint\n",
    "all_results = []\n",
    "\n",
    "for step, ckpt_path in checkpoints:\n",
    "    result = evaluate_checkpoint(step, ckpt_path, args)\n",
    "    if result is not None:\n",
    "        all_results.append(result)\n",
    "        \n",
    "        temp_csv = os.path.join(args.exp_dir, f\"{args.output_name}_temp.csv\")\n",
    "        pd.DataFrame(all_results).to_csv(temp_csv, index=False)\n",
    "\n",
    "# 保存结果\n",
    "if all_results:\n",
    "    df = pd.DataFrame(all_results)\n",
    "    df = df.sort_values('step')\n",
    "    \n",
    "    csv_path = os.path.join(args.exp_dir, f\"{args.output_name}.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Results saved to: {csv_path}\")\n",
    "    \n",
    "    json_path = os.path.join(args.exp_dir, f\"{args.output_name}.json\")\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    print(f\"JSON results saved to: {json_path}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"Checkpoint Performance Summary\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    best_idx = df['wikitext103_ppl'].idxmin()\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"Best Checkpoint\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Step: {df.loc[best_idx, 'step']}, PPL: {df.loc[best_idx, 'wikitext103_ppl']:.2f}\")\n",
    "    \n",
    "    if not args.skip_plot:\n",
    "        try:\n",
    "            plot_perplexity(df, args.exp_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting: {e}\")\n",
    "    \n",
    "    temp_csv = os.path.join(args.exp_dir, f\"{args.output_name}_temp.csv\")\n",
    "    if os.path.exists(temp_csv):\n",
    "        os.remove(temp_csv)\n",
    "        \n",
    "else:\n",
    "    print(\"No results to save!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyvit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
